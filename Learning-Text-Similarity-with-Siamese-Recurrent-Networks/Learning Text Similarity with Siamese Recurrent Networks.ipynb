{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d1e0721",
      "metadata": {
        "id": "9d1e0721"
      },
      "source": [
        "## Learning Text Similarity with Siamese Recurrent Networks\n",
        "\n",
        "https://aclanthology.org/W16-1617.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95ebf68",
      "metadata": {
        "id": "e95ebf68"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c33b88ae",
      "metadata": {
        "id": "c33b88ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f46b003",
      "metadata": {
        "id": "9f46b003"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(path):\n",
        "    df = pd.read_csv(path, sep='\\t', lineterminator='\\n',header=None)\n",
        "    df = df.rename(columns = {0:'name1',1:'name2',3:'label'})\n",
        "    x1 = []\n",
        "    x2 = []\n",
        "    label = []\n",
        "    name1 = df.name1.values.tolist()\n",
        "    name2 = df.name2.values.tolist()\n",
        "    for n1,n2 in zip(name1,name2):\n",
        "        if random.random()>0.5:\n",
        "            x1.append(n1)\n",
        "            x2.append(n2)\n",
        "        else:\n",
        "            x1.append(n2)\n",
        "            x2.append(n1)\n",
        "        label.append(1)\n",
        "    all_name = np.asarray(name1+name2)\n",
        "    shuffle_name = all_name[np.random.permutation(np.arange(len(all_name)))]\n",
        "    for n1,n2 in zip(all_name,shuffle_name):\n",
        "        if random.random()>0.5:\n",
        "            x1.append(n1)\n",
        "            x2.append(n2)\n",
        "        else:\n",
        "            x1.append(n2)\n",
        "            x2.append(n1)\n",
        "        label.append(0)\n",
        "    return pd.DataFrame({'name1':x1,'name2':x2,'label':label})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6c76118a",
      "metadata": {
        "id": "6c76118a"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/ujjalkumarmaity/research-paper-implementation/main/Learning-Text-Similarity-with-Siamese-Recurrent-Networks/person_match.train2'\n",
        "df = prepare_dataset(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "995b1d39",
      "metadata": {
        "id": "995b1d39"
      },
      "outputs": [],
      "source": [
        "MAX_SEQ_LEN = 70\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cf31a88b",
      "metadata": {
        "id": "cf31a88b"
      },
      "outputs": [],
      "source": [
        "def prepere_training_data(df,tokenizer):\n",
        "    name1_seq = tokenizer.texts_to_sequences(df['name1'])\n",
        "    name2_seq = tokenizer.texts_to_sequences(df['name2'])\n",
        "\n",
        "    name1_seq = pad_sequences(name1_seq,maxlen=MAX_SEQ_LEN)\n",
        "    name2_seq = pad_sequences(name2_seq,maxlen=MAX_SEQ_LEN)\n",
        "    return name1_seq,name2_seq,df['label'].values\n",
        "\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df['name1'])\n",
        "train,test = train_test_split(df,test_size=0.2,stratify = df['label'])\n",
        "train_text2seq_1,train_text2seq_2,train_label = prepere_training_data(train,tokenizer)\n",
        "test_text2seq_1,test_text2seq_2,test_label = prepere_training_data(test,tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c46d26",
      "metadata": {
        "id": "a5c46d26"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "724b71aa",
      "metadata": {
        "id": "724b71aa",
        "outputId": "6d6b0f37-b96c-4398-fc56-d2fe16a6e230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_word = len(tokenizer.word_index)+1\n",
        "def euclidean_distance(vects):\n",
        "    \"\"\"Find the Euclidean distance between two vectors.\n",
        "\n",
        "    Arguments:\n",
        "        vects: List containing two tensors of same length.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing euclidean distance\n",
        "        (as floating point value) between vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "def cosine_distanct(vests):\n",
        "    x,y = vests\n",
        "    x = K.l2_normalize(x, axis=-1)\n",
        "    y = K.l2_normalize(y, axis=-1)\n",
        "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "def cosine_distanct_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0],1)\n",
        "\n",
        "embdding_layer = layers.Embedding(num_word,output_dim=16,mask_zero=False)\n",
        "\n",
        "lstm_layer_1 = layers.Bidirectional(layers.LSTM(64,return_sequences=True))\n",
        "lstm_layer_2 = layers.Bidirectional(layers.LSTM(64,return_sequences=True))\n",
        "\n",
        "inp_seq1 = layers.Input(shape=(MAX_SEQ_LEN,))\n",
        "inp_seq2 = layers.Input(shape=(MAX_SEQ_LEN,))\n",
        "\n",
        "x1 = embdding_layer(inp_seq1)\n",
        "x1 = layers.BatchNormalization()(x1)\n",
        "\n",
        "# print(x1.shape)\n",
        "x1 = lstm_layer_1(x1)\n",
        "# print(x1.shape)\n",
        "\n",
        "x1 = lstm_layer_2(x1)\n",
        "x1 = layers.GlobalAveragePooling1D()(x1)\n",
        "x1 = layers.Dense(128)(x1)\n",
        "\n",
        "x2 = embdding_layer(inp_seq2)\n",
        "x2 = layers.BatchNormalization()(x2)\n",
        "x2 = lstm_layer_1(x2)\n",
        "x2 = lstm_layer_2(x2)\n",
        "x2 = layers.GlobalAveragePooling1D()(x2)\n",
        "x2 = layers.Dense(128)(x2)\n",
        "\n",
        "merge = layers.Lambda(euclidean_distance)([x1, x2])\n",
        "merge = layers.BatchNormalization()(merge)\n",
        "out = layers.Dense(1,activation='sigmoid')(merge)\n",
        "\n",
        "model = Model(inputs=[inp_seq1,inp_seq2],outputs = out)\n",
        "opt = SGD(lr=0.01)\n",
        "# model.compile(optimizer=opt,loss='binary_crossentropy',metrics='acc')\n",
        "# model.fit([train_text2seq_1,train_text2seq_2,],train_label,epochs=5,batch_size=64,verbose=1,\n",
        "#           validation_data=([test_text2seq_1,test_text2seq_2],test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c764ffe0",
      "metadata": {
        "id": "c764ffe0"
      },
      "outputs": [],
      "source": [
        "def loss(margin=1):\n",
        "    \"\"\"Provides 'contrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "    Arguments:\n",
        "        margin: Integer, defines the baseline for distance for which pairs\n",
        "                should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "    Returns:\n",
        "        'contrastive_loss' function with data ('margin') attached.\n",
        "    \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        \"\"\"Calculates the contrastive loss.\n",
        "\n",
        "        Arguments:\n",
        "            y_true: List of labels, each label is of type float32.\n",
        "            y_pred: List of predictions of same length as of y_true,\n",
        "                    each label is of type float32.\n",
        "\n",
        "        Returns:\n",
        "            A tensor containing contrastive loss as floating point value.\n",
        "        \"\"\"\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "98ff1d6e",
      "metadata": {
        "id": "98ff1d6e",
        "outputId": "91962b39-2eb1-4759-cfa2-32be6968a9e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 70, 16)       1184        ['input_3[0][0]',                \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 70, 16)      64          ['embedding_1[0][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 70, 16)      64          ['embedding_1[1][0]']            \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 70, 128)     41472       ['batch_normalization_1[0][0]',  \n",
            " )                                                                'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 70, 128)     98816       ['bidirectional_2[0][0]',        \n",
            " )                                                                'bidirectional_2[1][0]']        \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 128)         0           ['bidirectional_3[0][0]']        \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 128)         0           ['bidirectional_3[1][0]']        \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          16512       ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          16512       ['global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1)            0           ['dense_3[0][0]',                \n",
            "                                                                  'dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 1)           4           ['lambda_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            2           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 174,630\n",
            "Trainable params: 174,564\n",
            "Non-trainable params: 66\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "margin =1\n",
        "model.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ace9338f",
      "metadata": {
        "id": "ace9338f",
        "outputId": "0f863d1c-dc22-45f6-d697-a62a810bb9b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "495/495 [==============================] - 330s 627ms/step - loss: 0.2343 - accuracy: 0.6242 - val_loss: 0.2370 - val_accuracy: 0.5842\n",
            "Epoch 2/5\n",
            "495/495 [==============================] - 300s 606ms/step - loss: 0.2182 - accuracy: 0.6611 - val_loss: 0.2255 - val_accuracy: 0.6666\n",
            "Epoch 3/5\n",
            "495/495 [==============================] - 290s 586ms/step - loss: 0.2163 - accuracy: 0.6627 - val_loss: 0.2098 - val_accuracy: 0.6718\n",
            "Epoch 4/5\n",
            "495/495 [==============================] - 287s 580ms/step - loss: 0.2055 - accuracy: 0.6705 - val_loss: 0.2096 - val_accuracy: 0.6348\n",
            "Epoch 5/5\n",
            "495/495 [==============================] - 292s 591ms/step - loss: 0.2013 - accuracy: 0.6758 - val_loss: 0.2023 - val_accuracy: 0.6731\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cebf3e45db0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit([train_text2seq_1,train_text2seq_2,],train_label,epochs=5,batch_size=64,verbose=1,\n",
        "          validation_data=([test_text2seq_1,test_text2seq_2],test_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5a0a92",
      "metadata": {
        "id": "6f5a0a92"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}