{"cells":[{"cell_type":"markdown","metadata":{},"source":["## DPR(Dense Passage Retrieval) for Open-Domain Question Answering\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-02T09:18:45.005201Z","iopub.status.busy":"2024-06-02T09:18:45.004250Z","iopub.status.idle":"2024-06-02T09:18:45.904110Z","shell.execute_reply":"2024-06-02T09:18:45.903197Z","shell.execute_reply.started":"2024-06-02T09:18:45.005153Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:06.825080Z","iopub.status.busy":"2024-06-02T09:19:06.824569Z","iopub.status.idle":"2024-06-02T09:19:13.027154Z","shell.execute_reply":"2024-06-02T09:19:13.026224Z","shell.execute_reply.started":"2024-06-02T09:19:06.825049Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import transformers\n","from transformers import BertModel,BertConfig,BertTokenizer\n","from transformers import DistilBertConfig,DistilBertModel,DistilBertTokenizer,AutoModel\n","from torch.utils.data import DataLoader,Dataset\n","import pandas as pd\n","import numpy as np\n","from typing import Any,Dict\n","import random\n","import logging\n","logging.disable(logging.WARNING)"]},{"cell_type":"markdown","metadata":{},"source":["## Initilize Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:13.046963Z","iopub.status.busy":"2024-06-02T09:19:13.046729Z","iopub.status.idle":"2024-06-02T09:19:13.056224Z","shell.execute_reply":"2024-06-02T09:19:13.055301Z","shell.execute_reply.started":"2024-06-02T09:19:13.046935Z"},"trusted":true},"outputs":[],"source":["from transformers import BertTokenizer,DistilBertTokenizer\n","class HFBertTokenizer():\n","    def __init__(self,tokenizer:BertTokenizer,max_length :int,pad_to_max:bool ) -> None:\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.pad_to_max = pad_to_max\n","    def text_to_tensor(self,text,title=None,apply_max_len=True,add_special_tokens=True):\n","        if title:\n","            token_ids = self.tokenizer(title,text_pair=text,return_tensors='pt',max_length=self.max_length,truncation=True,padding=\"max_length\")\n","        else:\n","            token_ids = self.tokenizer(text,return_tensors='pt',max_length=self.max_length,truncation=True,padding=\"max_length\")\n","\n","        return token_ids\n","\n","    def get_tokenizer(self):\n","        return self.tokenizer\n","class HFDistilBertTokenizer(HFBertTokenizer):\n","    def __init__(self, tokenizer, max_length: int,pad_to_max:bool ) -> None:\n","        super().__init__(tokenizer, max_length,pad_to_max)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:13.069328Z","iopub.status.busy":"2024-06-02T09:19:13.069122Z","iopub.status.idle":"2024-06-02T09:19:15.813554Z","shell.execute_reply":"2024-06-02T09:19:15.812626Z","shell.execute_reply.started":"2024-06-02T09:19:13.069287Z"},"trusted":true},"outputs":[],"source":["bert_tokenozer = BertTokenizer.from_pretrained('bert-base-uncased')\n","hf_tokenizer = HFBertTokenizer(tokenizer=bert_tokenozer,max_length=200,pad_to_max = True)"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:15.815623Z","iopub.status.busy":"2024-06-02T09:19:15.815402Z","iopub.status.idle":"2024-06-02T09:19:15.819451Z","shell.execute_reply":"2024-06-02T09:19:15.818616Z","shell.execute_reply.started":"2024-06-02T09:19:15.815598Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","DATA_PATH = 'biencoder-nq-train-sample.json'\n","dataset = load_dataset(\"json\", data_files=DATA_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:15.870569Z","iopub.status.busy":"2024-06-02T09:19:15.870010Z","iopub.status.idle":"2024-06-02T09:19:15.874981Z","shell.execute_reply":"2024-06-02T09:19:15.874154Z","shell.execute_reply.started":"2024-06-02T09:19:15.870538Z"},"trusted":true},"outputs":[],"source":["import random\n","hf_tokenizer = HFBertTokenizer(tokenizer=bert_tokenozer,max_length=200,pad_to_max = True)\n","# hf_tokenizer = HFDistilBertTokenizer(tokenizer=dist_tokenozer,max_length=200,pad_to_max = True)\n","def tokenize_data(x,num_neg = 5 ,num_hard_neg = 5):\n","    pos_ctxs = x['positive_ctxs']\n","    pos_ctx = pos_ctxs[np.random.choice(len(pos_ctxs))]\n","    neg_ctxs = x['negative_ctxs']# [:num_neg]\n","    hard_neg_ctxs = x['hard_negative_ctxs']# [:num_hard_neg]\n","    all_neg_ctxs = hard_neg_ctxs + neg_ctxs\n","#     random.shuffle(all_neg_ctxs\n","    all_neg_ctxs = all_neg_ctxs[:num_neg+num_hard_neg]\n","    \n","    q = x['question']\n","    q_tensor = hf_tokenizer.text_to_tensor(text=q)\n","    all_ctxs = [pos_ctx] + all_neg_ctxs\n","    neg_ctxs_title = [\"\" if i.get(\"title\") is None else i.get(\"title\") for i in all_ctxs]\n","    neg_ctxs_text = [\"\" if i.get(\"text\") is None else i.get(\"text\") for i in all_ctxs ]\n","    all_ctxs_tensor = hf_tokenizer.text_to_tensor(text=neg_ctxs_text,title=neg_ctxs_title)\n","    return {\"q_input_ids\":q_tensor['input_ids'],\"q_attention_mask\":q_tensor['attention_mask'],\n","            \"all_ctxs_input_ids\":all_ctxs_tensor['input_ids'],\"all_ctxs_attention_mask\":all_ctxs_tensor['attention_mask']}\n","\n","\n","num_hard_neg = 5\n","num_neg = 5\n","\n","dataset = dataset.map(tokenize_data,\n","                            num_proc=2,\n","                            fn_kwargs={\"num_hard_neg\": num_hard_neg, \"num_neg\": num_neg},\n","                            remove_columns=[ 'hard_negative_ctxs', 'question', 'negative_ctxs', 'positive_ctxs'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:16.159221Z","iopub.status.busy":"2024-06-02T09:19:16.158937Z","iopub.status.idle":"2024-06-02T09:19:16.163565Z","shell.execute_reply":"2024-06-02T09:19:16.162657Z","shell.execute_reply.started":"2024-06-02T09:19:16.159190Z"},"trusted":true},"outputs":[],"source":["# save tokenize data\n","dataset.save_to_disk(\"biencoder-nq-train-tokenize-data-bert.hf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:16.928640Z","iopub.status.busy":"2024-06-02T09:19:16.928092Z","iopub.status.idle":"2024-06-02T09:19:20.407287Z","shell.execute_reply":"2024-06-02T09:19:20.406365Z","shell.execute_reply.started":"2024-06-02T09:19:16.928602Z"},"trusted":true},"outputs":[],"source":["from datasets import load_from_disk\n","from datasets import set_caching_enabled\n","set_caching_enabled(False)\n","\n","dataset = load_from_disk(\"biencoder-nq-train-tokenize-data-bert.hf\",keep_in_memory=True)\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:20.426809Z","iopub.status.busy":"2024-06-02T09:19:20.426290Z","iopub.status.idle":"2024-06-02T09:19:20.461149Z","shell.execute_reply":"2024-06-02T09:19:20.460224Z","shell.execute_reply.started":"2024-06-02T09:19:20.426783Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:23.835445Z","iopub.status.busy":"2024-06-02T09:19:23.835140Z","iopub.status.idle":"2024-06-02T09:19:23.841742Z","shell.execute_reply":"2024-06-02T09:19:23.841007Z","shell.execute_reply.started":"2024-06-02T09:19:23.835416Z"},"trusted":true},"outputs":[],"source":["train_dataset = dataset['train']\n","test_dataset = dataset['test']"]},{"cell_type":"markdown","metadata":{},"source":["## Initilize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:28.267379Z","iopub.status.busy":"2024-06-02T09:19:28.267122Z","iopub.status.idle":"2024-06-02T09:19:40.544066Z","shell.execute_reply":"2024-06-02T09:19:40.543124Z","shell.execute_reply.started":"2024-06-02T09:19:28.267352Z"},"trusted":true},"outputs":[],"source":["model = BertModel.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:40.565887Z","iopub.status.busy":"2024-06-02T09:19:40.565684Z","iopub.status.idle":"2024-06-02T09:19:40.577245Z","shell.execute_reply":"2024-06-02T09:19:40.576345Z","shell.execute_reply.started":"2024-06-02T09:19:40.565863Z"},"trusted":true},"outputs":[],"source":["class HFEncoderModel(nn.Module):\n","    def __init__(self, model_path = None,project_dim=768):\n","        super(HFEncoderModel,self).__init__()\n","        if model_path is None:\n","            self.model = BertModel.from_pretrained(\"bert-base-uncased\")\n","            for param in self.model.parameters():\n","                param.requires_grad = False\n","        else:\n","            self.model = BertModel.from_pretrained(model_path)\n","\n","        self.encoder_proj = nn.Linear(768,project_dim)\n","\n","\n","    def forward(self,\n","                input_ids,\n","                attention_mask,\n","                pooling = 'cls'):\n","        # print(input_ids.size(),attention_mask.size())\n","        out = self.model(input_ids = input_ids, attention_mask= attention_mask)\n","        ecnoder_out = out.last_hidden_state\n","        if pooling=='cls':\n","            ecnoder_out = ecnoder_out[:,0,:]\n","        else:\n","            NotImplementedError()\n","\n","        ecnoder_out = self.encoder_proj(ecnoder_out)\n","        return ecnoder_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:40.587791Z","iopub.status.busy":"2024-06-02T09:19:40.587599Z","iopub.status.idle":"2024-06-02T09:19:40.596219Z","shell.execute_reply":"2024-06-02T09:19:40.595468Z","shell.execute_reply.started":"2024-06-02T09:19:40.587768Z"},"trusted":true},"outputs":[],"source":["class BIEncoder(nn.Module):\n","    def __init__(self, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.query_encoder = HFEncoderModel()\n","        self.doc_encoder = HFEncoderModel()\n","\n","    @staticmethod\n","    def get_token_representation(sub_model,tokenize):\n","        return sub_model(**tokenize)\n","\n","    def forward(self,question_idx,ctx_idx):\n","        q_encoder = self.get_token_representation(self.query_encoder , question_idx)\n","        ctx_encoder = self.get_token_representation(self.doc_encoder , ctx_idx)\n","        return q_encoder,ctx_encoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:40.597553Z","iopub.status.busy":"2024-06-02T09:19:40.597324Z","iopub.status.idle":"2024-06-02T09:19:40.609677Z","shell.execute_reply":"2024-06-02T09:19:40.608887Z","shell.execute_reply.started":"2024-06-02T09:19:40.597517Z"},"trusted":true},"outputs":[],"source":["def calculate_total_num_parameter(model):\n","    # calculate total number of modle parameter and total number of trainable parameter\n","    total_num_param = 0\n","    total_num_trainable_param = 0\n","\n","    for param in model.parameters():\n","        if param.requires_grad:\n","            total_num_trainable_param += param.numel()\n","        total_num_param += param.numel()\n","    return total_num_param,total_num_trainable_param\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:48.707475Z","iopub.status.busy":"2024-06-02T09:19:48.706786Z","iopub.status.idle":"2024-06-02T09:19:50.015549Z","shell.execute_reply":"2024-06-02T09:19:50.014608Z","shell.execute_reply.started":"2024-06-02T09:19:48.707442Z"},"trusted":true},"outputs":[],"source":["model = BIEncoder()\n","calculate_total_num_parameter(model)"]},{"cell_type":"markdown","metadata":{},"source":["## Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:50.585610Z","iopub.status.busy":"2024-06-02T09:19:50.585373Z","iopub.status.idle":"2024-06-02T09:19:50.593580Z","shell.execute_reply":"2024-06-02T09:19:50.592601Z","shell.execute_reply.started":"2024-06-02T09:19:50.585581Z"},"trusted":true},"outputs":[],"source":["from torch.optim.lr_scheduler import LambdaLR\n","from torch.optim import AdamW\n","def get_optimizer(model_param,learning_rate: float = 1e-5,adam_eps: float = 1e-8,) -> torch.optim.Optimizer:\n","\n","    optimizer = AdamW(model_param, lr=learning_rate, eps=adam_eps)\n","    return optimizer\n","\n","def get_schedule_linear(\n","    optimizer,\n","    warmup_steps,\n","    total_training_steps,\n","    steps_shift=0,\n","    last_epoch=-1,\n","):\n","\n","    \"\"\"Create a schedule with a learning rate that decreases linearly after\n","    linearly increasing during a warmup period.\n","    \"\"\"\n","\n","    def lr_lambda(current_step):\n","        current_step += steps_shift\n","        if current_step < warmup_steps:\n","            return float(current_step) / float(max(1, warmup_steps))\n","        return max(\n","            1e-7,\n","            float(total_training_steps - current_step) / float(max(1, total_training_steps - warmup_steps)),\n","        )\n","\n","    return LambdaLR(optimizer, lr_lambda, last_epoch)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:52.432618Z","iopub.status.busy":"2024-06-02T09:19:52.431887Z","iopub.status.idle":"2024-06-02T09:19:52.440949Z","shell.execute_reply":"2024-06-02T09:19:52.440008Z","shell.execute_reply.started":"2024-06-02T09:19:52.432589Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","class NegativeLogLikeHood(nn.Module):\n","    def __init__(self):\n","        super(NegativeLogLikeHood, self).__init__()\n","    def forward(self,query_vec,pos_neg_vec):\n","        batch_size,_ = query_vec.size()\n","        pos_vec = pos_neg_vec[:,0,:]\n","        neg_vec = pos_neg_vec[:,1:,:]\n","        pos_sim = torch.sum(query_vec * pos_vec, dim=-1) #[batch_size]\n","        neg_sim = torch.bmm(neg_vec, query_vec.unsqueeze(-1)).squeeze(-1)  # [batch_size,num_negative]\n","        \n","        pos_sim_expand = pos_sim.unsqueeze(1)\n","        all_sim = torch.cat([pos_sim_expand,neg_sim],dim=1)\n","        softmax_scores = F.log_softmax(all_sim, dim=1)\n","        \n","        target = torch.zeros(batch_size,dtype=torch.long).to(query_vec.device)\n","        loss = F.nll_loss(softmax_scores, target)\n","        return loss"]},{"cell_type":"markdown","metadata":{},"source":["## Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:55.105059Z","iopub.status.busy":"2024-06-02T09:19:55.104339Z","iopub.status.idle":"2024-06-02T09:19:55.112002Z","shell.execute_reply":"2024-06-02T09:19:55.111179Z","shell.execute_reply.started":"2024-06-02T09:19:55.105027Z"},"trusted":true},"outputs":[],"source":["def top_k_accuracy(query_vec,pos_neg_vec,k=3):\n","    batch_size,_ = query_vec.size()\n","    pos_vec = pos_neg_vec[:,0,:]\n","    neg_vec = pos_neg_vec[:,1:,:]\n","    pos_sim = torch.sum(query_vec * pos_vec, dim=-1) #[batch_size]\n","    neg_sim = torch.bmm(neg_vec, query_vec.unsqueeze(-1)).squeeze(-1)  # [batch_size,num_negative]\n","\n","    pos_sim_expand = pos_sim.unsqueeze(1)\n","    all_sim = torch.cat([pos_sim_expand,neg_sim],dim=1)\n","    target = torch.zeros(batch_size,dtype=torch.long).to(query_vec.device)\n","    \n","    top_k_ind = torch.topk(all_sim,k=k,dim=1).indices\n","\n","    accuracy = (top_k_ind==target.unsqueeze(1)).sum().item()/batch_size\n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:58.408371Z","iopub.status.busy":"2024-06-02T09:19:58.408116Z","iopub.status.idle":"2024-06-02T09:19:58.417705Z","shell.execute_reply":"2024-06-02T09:19:58.416802Z","shell.execute_reply.started":"2024-06-02T09:19:58.408344Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch):\n","    batch_size = len(batch)\n","    num_ctx = len(batch[0]['all_ctxs_input_ids'])\n","    data = {\n","        'q_input_ids': torch.zeros(batch_size,200,dtype = torch.long),\n","        'q_attention_mask': torch.zeros(batch_size,200,dtype = torch.long),\n","        'all_ctxs_input_ids': torch.zeros(batch_size,num_ctx,200,dtype = torch.long),\n","        'all_ctxs_attention_mask': torch.zeros(batch_size,num_ctx,200,dtype = torch.long)\n","    }\n","    for ind,sample in enumerate(batch):\n","        for key,val in sample.items():\n","            if len(val)==1:\n","                data[key][ind,:] = torch.tensor(val)\n","            else:\n","                data[key][ind,:,:] = torch.tensor(val)\n","    data_final = {}\n","    for key,val in data.items():\n","        if len(val.size())==2:\n","            data_final[key] = val[:,torch.sum(val,axis=0).bool()]\n","        else:\n","            data_final[key] = val[:,:,torch.sum(val,axis=(0,1)).bool()]\n","\n","#     data1 = {key:val[:,torch.sum(val,axis=0).bool()] for key,val in data.items()}\n","    return data_final"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:19:59.152858Z","iopub.status.busy":"2024-06-02T09:19:59.152604Z","iopub.status.idle":"2024-06-02T09:20:09.892029Z","shell.execute_reply":"2024-06-02T09:20:09.891157Z","shell.execute_reply.started":"2024-06-02T09:19:59.152831Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","batch_size = 32\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    batch_size=batch_size,\n","    drop_last = True,\n","    pin_memory=True,\n","    num_workers= 2\n",")\n","\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    batch_size=batch_size,\n","    drop_last = True,\n","    pin_memory=True,\n","    num_workers= 2\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:20:13.201701Z","iopub.status.busy":"2024-06-02T09:20:13.201446Z","iopub.status.idle":"2024-06-02T09:20:13.209756Z","shell.execute_reply":"2024-06-02T09:20:13.208807Z","shell.execute_reply.started":"2024-06-02T09:20:13.201672Z"},"trusted":true},"outputs":[],"source":["epoch = 2\n","total_training_steps = len(train_dataloader) * epoch\n","max_seq_len = 200\n","ctx_sample = 11\n","\n","optimizer = get_optimizer(model.parameters())\n","scheduler = get_schedule_linear(optimizer=optimizer,warmup_steps=50,total_training_steps = total_training_steps)\n","loss_function = NegativeLogLikeHood()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:20:14.889736Z","iopub.status.busy":"2024-06-02T09:20:14.889481Z","iopub.status.idle":"2024-06-02T09:20:14.916699Z","shell.execute_reply":"2024-06-02T09:20:14.915765Z","shell.execute_reply.started":"2024-06-02T09:20:14.889709Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:20:48.119349Z","iopub.status.busy":"2024-06-02T09:20:48.119050Z","iopub.status.idle":"2024-06-02T09:20:48.130590Z","shell.execute_reply":"2024-06-02T09:20:48.129630Z","shell.execute_reply.started":"2024-06-02T09:20:48.119315Z"},"trusted":true},"outputs":[],"source":["# training\n","from tqdm import tqdm\n","def train_one_epoch(epoch_no):\n","    train_loss = 0\n","    c = 0\n","    progress_bar = tqdm(range(len(train_dataloader)))\n","    for tokenize_data in train_dataloader:\n","        b_size,num_ctx,max_seq_len = tokenize_data['all_ctxs_input_ids'].size()\n","        try:\n","            question_idx = {\"input_ids\":tokenize_data['q_input_ids'].to(device),\n","                            \"attention_mask\":tokenize_data['q_attention_mask'].to(device)}\n","\n","            ctx_idx = {\"input_ids\":tokenize_data['all_ctxs_input_ids'].view(num_ctx*b_size,max_seq_len).to(device),\n","                    \"attention_mask\":tokenize_data['all_ctxs_attention_mask'].view(num_ctx*b_size,max_seq_len).to(device)}\n","            q_embedd,ctx_embedd = model(question_idx,ctx_idx)\n","\n","            ctx_embedd = ctx_embedd.view(batch_size,-1,768)\n","            loss = loss_function(q_embedd,ctx_embedd)\n","            loss.backward()\n","            train_loss += loss.item()\n","\n","\n","            optimizer.step()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","            c+=1\n","            if c%200==0 and c>0:\n","                print(f\"epoch is {epoch_no},batch is {c+1}, loss is {loss.item()}\")\n","\n","            progress_bar.update(1)\n","        except:\n","            print(\"error\")\n","            pass\n","        \n","    return train_loss/len(train_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T09:21:46.731705Z","iopub.status.busy":"2024-06-02T09:21:46.731434Z"},"trusted":true},"outputs":[],"source":["# evaluation\n","best_vloss = 100_00\n","model.to(device)\n","for ep in range(epoch):\n","    model.train(True)\n","    avg_loss = train_one_epoch(ep)\n","    \n","    model.eval()\n","    total_val_loss = 0\n","    val_accuracy = 0\n","    with torch.no_grad():\n","        for i, vdata in enumerate(test_dataloader):\n","\n","            b_size,num_ctx,max_seq_len = vdata['all_ctxs_input_ids'].size()\n","            val_question_idx = {\"input_ids\":vdata['q_input_ids'].to(device),\n","                            \"attention_mask\":vdata['q_attention_mask'].to(device)}\n","\n","            val_ctx_idx = {\"input_ids\":vdata['all_ctxs_input_ids'].view(num_ctx*b_size,max_seq_len).to(device),\n","                    \"attention_mask\":vdata['all_ctxs_attention_mask'].view(num_ctx*b_size,max_seq_len).to(device)}\n","\n","            q_embedd,ctx_embedd = model(val_question_idx,val_ctx_idx)\n","\n","            ctx_embedd = ctx_embedd.view(batch_size,-1,768)\n","            val_accuracy += top_k_accuracy(q_embedd, ctx_embedd)\n","\n","            vloss = loss_function(q_embedd,ctx_embedd)\n","            total_val_loss += vloss\n","\n","    avg_loss = total_val_loss/len(test_dataloader)\n","    \n","    print(f\"validation loss = {avg_loss}, validation accuracy = {val_accuracy/len(test_dataloader)}\")\n","    if avg_loss<best_vloss:\n","        best_vloss = best_vloss\n","        torch.save(model.state_dict(), 'biencoder-model.pt')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":178543421,"sourceType":"kernelVersion"},{"sourceId":180937806,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
