## Paper Name :- Language Models are Unsupervised Multitask Learners
Author :- Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever

URL - https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf

## GPT-2 model architecture
<img src="https://www.researchgate.net/publication/373352176/figure/fig1/AS:11431281202501967@1698856108167/GPT-2-model-architecture-The-GPT-2-model-contains-N-Transformer-decoder-blocks-as-shown.ppm">